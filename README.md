# ğŸ§  License Plate Recognition using Large Language Model (LLM)

This repository contains the source code for a license plate OCR (Optical Character Recognition) system developed as part of the **Computer Vision (RE604)** coursework at Politeknik Negeri Batam.

The system uses a **Large Language Model (LLM)** (`qwen2-vl-2b-instruct`) via **LMStudio** to read license plate images and evaluate the results using **Character Error Rate (CER)**.

---

## ğŸ—‚ Directory Structure

```
project/
â”œâ”€â”€ generate_ground_truth.py                  # Convert YOLO labels to text
â”œâ”€â”€ run_ocr_and_evaluate.py                   # Run OCR and evaluate results
â”œâ”€â”€ ground_truth.csv                          # Ground truth text for each image
â”œâ”€â”€ ocr_results.csv                           # OCR results and CER scores
â””â”€â”€ archive/
    â””â”€â”€ Indonesian License Plate Recognition Dataset/
        â”œâ”€â”€ classes.names                     # Class ID to character mapping
        â”œâ”€â”€ images/
        â”‚   â””â”€â”€ test/                         # Test images of license plates
        â””â”€â”€ labels/
            â””â”€â”€ test/                         # YOLO label files
```

---

## ğŸ“Œ Project Description

This project is implemented in Python using the following tools:

- `lmstudio` â€“ interface to call the VLM model (`qwen2-vl-2b-instruct`)
- `pandas` â€“ to manage CSV data
- `evaluate` â€“ to calculate Character Error Rate (CER)
- `os`, `csv` â€“ for file processing and path management

The dataset used is the **Indonesian License Plate Dataset**, available on Kaggle:  
ğŸ‘‰ [Indonesian License Plate Dataset on Kaggle](https://www.kaggle.com/datasets/juanthomaswijaya/indonesian-license-plate-dataset)

> The license plate dataset is the **Indonesian License Plate Recognition Dataset**, consisting of images and YOLO-format labels.

---

## âš™ï¸ Methodology

1. **Ground Truth Generation**
   - Read YOLO `.txt` labels
   - Map class IDs to characters using `classes.names`
   - Sort characters by x-axis position
   - Save as `ground_truth.csv` (image name and license plate text)

2. **OCR with VLM**
   - Load each image
   - Send prompt to `qwen2-vl-2b-instruct` via LMStudio
   - Get model prediction

3. **Evaluation**
   - Compare prediction vs ground truth using **CER**
   - Log the results
   - Save to `ocr_results.csv`

---

## ğŸ§ª Evaluation Results

| Metric              | Value (example) |
|---------------------|-----------------|
| Average CER         | 0.0384          |
| Prediction Accuracy | Shown per image |

> The model's performance depends on image quality and label consistency. Lower CER means better OCR performance.

Example Output:

```bash
[âœ“] test001_1.jpg: GT=B9140BCD, Pred=B9140BCD, CER=0.0000
[âœ“] test001_2.jpg: GT=B2407UZO, Pred=B2407UZ0, CER=0.1250
[âœ“] test001_3.jpg: GT=B2842PKM, Pred=B2842PKM, CER=0.0000

ğŸ“Š Average CER: 0.0384
ğŸ“ Results saved to: ocr_results.csv

---

## ğŸ‘¤ Biodata

**Nama**: Daipansyah Arya Saputra  
**Universitas**: Politeknik Negeri Batam  
**Program Studi**: Robotika  
**Kelas**: RE 6A Pagi  

---

## ğŸ¥ Link Video
ğŸ‘‰ [Link](https://youtu.be/C5xjHdheqzM?si=izJjLAq8hDd4vg7L)


## ğŸ› ï¸ Installation

To install the required dependencies, run:

```bash
pip install scikit-learn scikit-image matplotlib numpy scipy